---
title: Python Introduction - Exercise Set
subtitle: ISEG Executive Education - PG AAIML
author: Diogo Silva
format:
    typst: default
    html:
        embed-resources: true
toc: true
---

Tips:

- Start by understanding what the exercise asks
- Break the problem into smaller steps
- Test your code with the provided examples
- Try variations of the solutions
- Don't hesitate to combine techniques you've learned
- For ML exercises: think about why these operations matter in real projects

**Tips for Module 3 Exercises:**
- Always use context managers (`with` statement) when working with files
- Use `pathlib.Path` instead of string manipulation for file paths
- Keep functions focused on a single task (single responsibility principle)
- Use meaningful function and parameter names
- Test edge cases (empty lists, missing files, invalid inputs)
- Remember that `map()` returns an iterator - convert to list if needed
- When creating modules, think about code organization and reusability


# Modules 1 and 2

## Exercise 1: Expense Tracker

You're managing your monthly expenses. Create a program that:
1. Stores your expenses in a list: `[1250.50, 89.90, 45.00, 320.75, 12.50]`
2. Calculates the total spent
3. Finds the average expense
4. Counts how many expenses were above 100€


## Exercise 2: Employee Database

You're building a simple employee management system. Create a dictionary with employee IDs as keys and their information as values (this information should also be a `dict`):

- Employee 101: Maria Silva, salary 2500, department "Sales"
- Employee 102: João Santos, salary 3200, department "IT"
- Employee 103: Ana Costa, salary 2800, department "Sales"

Then:
1. Print all employees with salary above 2600
2. Calculate the average salary for the Sales department
3. Add a new employee (104: Pedro Alves, salary 3500, department "IT")

Extra challenge: receive employees from the user with `input` inside a loop, only stop when employee number is a negative number.


## Exercise 3: Product Inventory

A small shop needs to manage its inventory. Create a program that:
1. Stores products as tuples: (product_name, quantity, price)
2. Creates a list with these products: `("Laptop", 5, 899.99), ("Mouse", 23, 15.50), ("Keyboard", 12, 45.00)`
3. Finds products with quantity below 10
4. Calculates total inventory value
5. Creates a dictionary mapping product names to their stock quantity


## Exercise 5: Sales Report Generator

You have daily sales data for a week. Create a program that:
1. Stores sales in a list: `[1200, 1450, 980, 1100, 1650, 890, 1320]`
2. Identifies which days had sales above average
3. Finds the best and worst sales days
4. Creates a dictionary with day names (Monday-Sunday) and sales values


## Exercise 6: Password Validator

Create a simple password validator that checks if a password:
1. Is at least 8 characters long
2. Contains at least one number
3. Contains both uppercase and lowercase letters

Test with: "Secure123", "weak", "NOLOWER1", "noupper1"

---

## Exercise 7: Shopping Cart

Simulate a shopping cart system:
1. Create a dictionary with products and prices: {`"apple": 0.50, "bread": 1.20, "milk": 0.90, "cheese": 2.50}`
2. Create an empty cart (list of tuples: product name and quantity)
3. Add items to cart: 3 apples, 1 bread, 2 milk
4. Calculate total cost
5. Apply a 10% discount if total is above 5€

## Exercise 8: Text Analyzer

Create a program that analyzes a piece of text:
1. Count total words
2. Count how many words start with a vowel
3. Find the longest word
4. Create a dictionary with word lengths as keys and list of words as values

Test with: "Python programming is powerful and versatile"

Added challenge - Bag of words: count the occurence of each word in a text; test with the text in this [link](https://www.gutenberg.org/cache/epub/75201/pg75201.txt)

Added challenge 2 - n-gram counter: instead of words, count the number of times `n` letters appear together, e.g. "Instituto" leads to trigrams (3-gram) "ins" "nst" "sti"  "tit" "itu" "tut" "uto", but there is no repetition here; make it so `n` is a parameter, i.e. you can easily change it in a variable, and the rest of the logic remains intact.



## Exercise 9: Learning Rate Scheduler (ML)

Create a [learning rate scheduler](https://neptune.ai/blog/how-to-choose-a-learning-rate-scheduler) that reduces the learning rate by 50% every 10 epochs. Start with LR=0.1 and simulate 35 epochs. Track and display the learning rate at each epoch.


## Exercise 10: Meeting Scheduler

You're scheduling meetings for a week. Create a program that:
1. Stores meeting slots as tuples: (day, hour, duration_minutes, attendees_count)
2. Create a list with: `("Monday", 10, 60, 5), ("Monday", 14, 30, 3), ("Tuesday", 9, 90, 8), ("Wednesday", 11, 45, 4)`
3. Calculate total meeting hours for the week
4. Find the busiest day (most total meeting time)
5. Calculate average number of attendees per meeting
6. Create a dictionary with days as keys and list of meetings as values




## Exercise 11: Dataset Preparation

You're preparing a dataset for training. You have raw data with missing values represented as -999:
- Features: `[1.2, 3.4, -999, 5.6, 2.1, -999, 4.5, 3.2]`

Create a program that:
1. Counts how many missing values exist
2. Replaces missing values with the mean of valid values
3. Normalizes all values to 0-1 range (min-max scaling)
4. Prints original vs processed data side-by-side


## Exercise 12: Model Performance Tracker

You're training multiple models and need to track their performance. Create a system that:
1. Stores model results as dictionaries with: model_name, accuracy, training_time (minutes), parameters_count
2. Creates a list with results for: `RandomForest (0.87, 12, 500000), NeuralNet (0.91, 45, 1200000), LogisticRegression (0.82, 3, 50000), SVM (0.85, 8, 200000)`
3. Finds the best model by accuracy
4. Calculates the average training time
5. Identifies models with accuracy > 0.85 and training time < 15 minutes

Note you might want to this exercise with [exercise 21](#exercise-21-experiment-logger).

## Exercise 13: Training Data Splitter

You have a dataset of 100 samples that need to be split into training (70%), validation (20%), and test (10%) sets. Create a program that:
1. Creates a list of sample IDs from 0 to 99
2. Splits them into three sets following the percentages
3. Verifies no overlap between sets
4. Prints the size of each set and first 5 IDs from each


Extra challenge: randomly sample the samples for each set; hint: use the built-in `random` module.

---

## Exercise 14: Confusion Matrix Calculator

You have predictions from a binary classifier. Create a program that:
1. Takes actual labels: `[1, 0, 1, 1, 0, 1, 0, 0, 1, 0]`
2. Takes predictions: `[1, 0, 1, 0, 0, 1, 1, 0, 1, 0]`
3. Calculates True Positives, True Negatives, False Positives, False Negatives
4. Computes Accuracy, Precision, and Recall
5. Displays the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)



## Exercise 15: Feature Engineering Pipeline

You have raw sensor data and need to create features.
Given temperature readings: `[20.5, 21.3, 22.1, 21.8, 23.2, 24.1, 23.5, 22.9]`

Create a program that generates these features:
1. Moving average (window size 3)
2. Temperature difference from previous reading
3. Boolean feature: is_increasing (compared to previous)
4. Store all features in a dictionary with descriptive keys


---

## Exercise 16: Hyperparameter Grid Generator

You need to create all combinations of hyperparameters for grid search. Generate combinations for:
- learning rate: `[0.001, 0.01, 0.1]`
- batch size: `[8, 16, 32, 64]`
- epochs: `[10, 20]`

Create a program that:
1. Generates all possible combinations
2. Counts total combinations
3. Estimates total training time (assume each takes 5 minutes)
4. Stores combinations in a list of dictionaries

**Extra challenge - parameters with dependencies**
Consider that this model has some architectural modules which can be easily swapped: a feature extractor and an aggregation head. The feature extractors include `resnet18`, `resnet50`, `resnet100`, `resnet152` and `ViT`. The heads include `GeM`, `NetVLAD` and `MLP`.
For `resnet100` and `resnet152`, batch size may not be higher than 8.
For `ViT`, `NetVLAD` will not work.
Redo the exercise with these 2 added parameters, and with the dependencies in mind.

Note: this kind of logic is not supported in most built-in libraries, e.g. Scikit-Learn.


## Exercise 17: Label Distribution Analyzer

You have a dataset with class labels. Analyze if there's class imbalance:
- Labels: `[0, 1, 0, 0, 1, 2, 0, 1, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0]`

Create a program that:
1. Counts samples per class
2. Calculates the percentage distribution
3. Identifies if dataset is imbalanced (majority class > 60%)
4. Suggests whether resampling might be needed
5. Creates a dictionary mapping class labels to their counts

Extra challenge: sample classes so that number of samples per class is roughly the same.

## Exercise 18: Batch Data Generator

Simulate creating batches for training. You have 47 samples and need to create batches of size 8.

Create a program that:
1. Creates sample IDs (0 to 46)
2. Splits them into batches of 8
3. Handles the last incomplete batch
4. Shows how many full batches and the size of the last batch
5. Stores batches in a list of lists





# Module 3

## Exercise 19: Boston Housing Dataset - Data Normalization

In this exercise, you will work with a real dataset - the well known Boston House Prices dataset.
You can download it from [here](assets/data/BostonHousing.csv) or find it easily online (e.g. Kaggle).
The exercise will require you to program the data loading functionality, as well as some basic normalization routines.

- **Data loading**
  - Create a function that will load the dataset, in Comma Seperated Values (CSV) format, and returns a `dict` with pairs of {column, list of values}.
  - The name of each column is specified in the first line of the CSV file.
  - Convert each value to float.
- **Scaling**
  - Write a function mean(values) that computes the mean of a list of values.
  - Write a function std(values) that computes the standard deviation of a list of numbers.
  - Output the mean and std of every column.
  - Write a function min_max_scale(values) that normalizes a list of numbers to the 0-1 range
  - Write a function standardize(values) that standardizes data (subtract mean, divide by standard deviation)
  - Write a function apply_scaling(data, method) that takes a list and a method name ("minmax" or "standard") and applies the appropriate scaling
  - Use `apply_scaling` with both methods to an arbitrary column and compare results.
- **Data card** (capitalized column name, followed by description)
  - CRIM per capita crime rate by town
  - ZN proportion of residential land zoned for lots over 25,000 sq.ft.
  - INDUS proportion of non-retail business acres per town
  - CHAS Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
  - NOX nitric oxides concentration (parts per 10 million)
  - RM average number of rooms per dwelling
  - AGE proportion of owner-occupied units built prior to 1940
  - DIS weighted distances to five Boston employment centres
  - RAD index of accessibility to radial highways
  - TAX full-value property-tax rate per $10,000
  - PTRATIO pupil-teacher ratio by town
  - B 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town
  - LSTAT % lower status of the population
  - MEDV Median value of owner-occupied homes in $1000's


## Exercise 20: Model Evaluation Module

Create a Python module called `ml_metrics.py` with functions to calculate classification metrics:

1. Function `accuracy(y_true, y_pred)` - returns accuracy score
2. Function `precision(y_true, y_pred)` - returns precision for class 1
3. Function `recall(y_true, y_pred)` - returns recall for class 1
4. Function `f1_score(y_true, y_pred)` - returns F1 score (harmonic mean of precision and recall)
5. Function `evaluate_model(y_true, y_pred)` - returns a dictionary with all metrics

In a separate notebook or script, import your module and test it with:
- y_true = `[1, 0, 1, 1, 0, 1, 0, 0, 1, 0]`
- y_pred = `[1, 0, 1, 0, 0, 1, 1, 0, 1, 0]`


## Exercise 21: Experiment Logger

Create a system that logs ML experiments to a text file:

1. Write a function `log_experiment(model_name, hyperparameters, metrics, filename="experiments.txt")` that appends experiment details to a file
2. The log entry should include: timestamp (you can use a simple counter), model name, hyperparameters (as dict), and metrics (as dict)
3. Write a function `read_experiments(filename="experiments.txt")` that reads and prints all logged experiments
4. Test by logging 3 different experiments with different models and hyperparameters
5. Use context managers for file operations


## Exercise 22: Dataset File Processor

You have multiple CSV files with training data from different sources. Create functions to process them:

1. Write a function `load_dataset(filepath)` that reads a CSV file and returns the data as a list of dictionaries (each row is a dict).
2. Write a function `filter_by_threshold(data, column, threshold)` that filters rows where a column value exceeds a threshold
3. Write a function `save_processed_data(data, output_path)` that saves the processed data to a new CSV file
4. Use `pathlib.Path` for file operations
5. Create a function `process_pipeline([input_file1, input_file2], output_file, column, threshold)` that combines all steps, but also accepts a list of input CSV files instead of just one. The data from those files must be combined before being fed to `filter_by_threshold` and `save_processed_data`.

Split the `BostonHousing.csv` [(link)](assets/data/BostonHousing.csv)dataset into 3 different files manually, e.g. first 100 rows for file 1, rows 100-200 for file 2, and the remaining rows for file 3.

## Exercise 23: Feature Transform Library

Create a module `transformers.py` with transformation functions and use `map` to apply them:

1. Function `log_transform(x)` - applies logarithmic transformation (handle x <= 0)
2. Function `square_transform(x)` - squares the value
3. Function `clip_outliers(x, lower, upper)` - clips values outside the range
4. Function `apply_transform(values, transform_func)` - uses `map()` to apply any transformation to a list. Note that what is being passed in the second argument is the actual function.

Test with: `[1, 5, 10, 50, 100, 500, 1000]`


## Exercise 25: Model Checkpoint Manager

See problem statement [here](exercise_25_checkpoint_manager.html)



## Exercise 27: Feature Selection Pipeline

Create functions to select the most informative features:

1. Function `calculate_variance(values)` - calculates variance of a feature
2. Function `select_high_variance_features(data_dict, threshold)` - data_dict has feature names as keys and lists of values as values. Use `filter()` to keep only features with variance above threshold
3. Function `save_selected_features(selected_features, filepath)` - saves the list of selected feature names to a file
4. Function `load_feature_config(filepath)` - loads the feature names from the file
5. Function `apply_feature_selection(data_dict, feature_names)` - returns a new dict with only the selected features

Test with `BostonHousing.csv` dataset [(link)](assets/data/BostonHousing.csv).

Reflection: What threshold should you pick? Should some normalization be applied first?

## Exercise 28: Cross-Validation Split Generator

Create a module for generating cross-validation splits using [k-fold](https://en.wikipedia.org/wiki/Cross-validation_(statistics)#k-fold_cross-validation):

1. Function `create_folds(data_indices, k=5)` - splits indices into k approximately equal folds and returns a list of folds
2. Function `get_train_test_split(folds, test_fold_index)` - given the folds and which fold to use as test, returns train and test indices
3. Function `save_cv_splits(folds, directory)` - saves each fold to a separate file (fold_0.txt, fold_1.txt, etc.) using pathlib
4. Function `load_cv_splits(directory)` - loads all fold files from the directory and returns them as a list
5. Write a function that uses `map()` to apply a validation function to all k folds

Test with 50 sample indices and k=5 folds.

Reflection: image you have an imbalanced dataset (class wise) - would you change anything when creating the folds?


## Exercise 29: Data Augmentation Generator

Create functions that generate augmented versions of data:

1. Function `add_noise(value, noise_level=0.1)` - adds [Gaussian noise](https://docs.python.org/3/library/random.html#random.gauss) to a value (simulate by adding/subtracting noise_level * value).
2. Function `scale_value(value, scale_factor)` - scales a value by a factor
3. Function `augment_sample(sample, augmentation_funcs)` - takes a list of values and a list of augmentation functions, applies all functions
4. Use `map()` to create augmented versions of an entire dataset
5. Function `save_augmented_data(original, augmented, filepath)` - saves both original and augmented data to a file with clear labels

Test with: `[1.0, 2.5, 3.7, 4.2, 5.8]` and create 2 augmented versions.

Added challenge: augment the `BostonHousing.csv` dataset [(link)](assets/data/BostonHousing.csv) and use column-wise variance for the random noise augmentation; 


## Exercise 30: Training Configuration Manager

Create a system to manage training configurations:

1. Function `create_config(learning_rate, batch_size, epochs, optimizer)` - returns a configuration dictionary
2. Function `save_config(config, filepath)` - saves the configuration to a text file in a readable format (key: value pairs)
3. Function `load_config(filepath)` - loads configuration from file and returns it as a dictionary
4. Function `validate_config(config)` - checks that all required keys exist and values are within reasonable ranges
5. Create a package structure with separate modules for config management and validation

Test by creating, saving, loading, and validating different configurations.

Tip: use the [`json` module](https://docs.python.org/3/library/json.html).



## Exercise 31: Ensemble Results Combiner
Create functions that combine predictions from multiple models (stored in separate files) using different strategies: majority voting for classification, averaging for regression. 

Added challenge: for classification, use the estimated confidence alongside the atual prediction for refining the final ensemble result.


Data:

```
# Mock Classification Predictions (3 models predicting classes 0, 1, 2)
model1_classification = """sample_id,prediction,confidence
0,1,0.85
1,0,0.92
2,2,0.78
3,1,0.88
4,0,0.95
5,2,0.71
6,1,0.83
7,0,0.89
8,2,0.76
9,1,0.91"""

model2_classification = """sample_id,prediction,confidence
0,1,0.82
1,0,0.88
2,1,0.65
3,1,0.90
4,0,0.93
5,2,0.68
6,1,0.86
7,1,0.72
8,2,0.81
9,1,0.87"""

model3_classification = """sample_id,prediction,confidence
0,1,0.79
1,0,0.91
2,2,0.73
3,0,0.67
4,0,0.96
5,1,0.62
6,1,0.84
7,0,0.85
8,2,0.79
9,1,0.89"""


# Model 1 Regression Predictions
model1_regression = """sample_id,prediction
0,42.5
1,38.2
2,55.7
3,61.3
4,29.8
5,48.9
6,52.1
7,45.6
8,33.4
9,58.2"""

# Model 2 Regression Predictions
model2_regression = """sample_id,prediction
0,43.1
1,37.8
2,54.9
3,62.5
4,30.2
5,49.5
6,51.8
7,46.2
8,34.1
9,57.8"""

# Model 3 Regression Predictions
model3_regression = """sample_id,prediction
0,42.8
1,38.5
2,56.2
3,60.9
4,29.5
5,48.2
6,52.5
7,45.1
8,33.8
9,58.9"""


ground_truth_classification = """sample_id,true_label
0,1
1,0
2,2
3,1
4,0
5,2
6,1
7,0
8,2
9,1"""

ground_truth_regression = """sample_id,true_value
0,42.7
1,38.0
2,55.5
3,61.5
4,30.0
5,49.0
6,52.0
7,45.5
8,33.5
9,58.5"""

```
